{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **L&T EduTech Hackathon**\n## **Submission for Problem Statement 1 -** Cement Surface Crack Detection\n## **Developed by:** Team Avinya","metadata":{"execution":{"iopub.status.busy":"2023-01-19T10:18:23.232356Z","iopub.execute_input":"2023-01-19T10:18:23.233497Z","iopub.status.idle":"2023-01-19T10:18:55.289039Z","shell.execute_reply.started":"2023-01-19T10:18:23.233383Z","shell.execute_reply":"2023-01-19T10:18:55.288188Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"markdown","source":"# **Problem Statement**\n\n### The problem statement is relatively simple but is highly relevant and has a huge practical impact factor. Remote enabling of surface crack detections can help in early, accurate and high precision detection without any human inference.\n\n### Given a surface image, the model should be able to find out if the surface has cracks, and accordingly classify it into Positive (has cracks) and Negative (no cracks)","metadata":{}},{"cell_type":"markdown","source":"# **Approach**\n\n* ### Since this is an image classification based problem, Deep Learning is a natural choice.\n* ### After some research, we have decided to go with a customized VGG16 model via transfer learning. The model provided a better performance than other popular architectures like ResNet and InceptionNet.","metadata":{}},{"cell_type":"markdown","source":"# **Dataset**\n\n### Since the provided dataset is quite small, we have also referred to an external dataset for the training of the model. The external dataset consists of 40,000 images equally divided into Positive and Negative Classes.\n\n* ### [Dataset 1](https://www.kaggle.com/datasets/xinzone/surface-crack)\n* ### [Dataset 2](https://www.kaggle.com/datasets/arunrk7/surface-crack-detection?datasetId=414522&sortBy=voteCount)","metadata":{}},{"cell_type":"markdown","source":"# **Dependencies**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nimport keras\nimport matplotlib.pyplot as plt\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport tensorflow as tf\n\nfrom matplotlib.image import imread\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import Model,layers\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:04:41.379966Z","iopub.execute_input":"2023-01-19T14:04:41.381466Z","iopub.status.idle":"2023-01-19T14:04:41.390122Z","shell.execute_reply.started":"2023-01-19T14:04:41.381394Z","shell.execute_reply":"2023-01-19T14:04:41.389124Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **VGG16 Model Setup**","metadata":{}},{"cell_type":"markdown","source":"* ### With reference to the original VGG16 architecture, we obtain the model through transfer learning and retain it upto the 'block5_pool' layer.\n* ### Ahead of it, a few customized layers are added sequentially, for task specific model training. \n* ### ReLU and Sigmoid activation functions have been used, along with RMSprop optimizer. The learning rate was found out using hyperparameter tuning and set to 0.0001.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\n\nweights_file='/kaggle/input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npretrained_model=VGG16(input_shape = (120, 120, 3), \n                        include_top = False, \n                        weights =None)\n\npretrained_model.load_weights(weights_file)\n\nfor layer in pretrained_model.layers:\n     layer.trainable = False\n\npretrained_model.summary()\n\nlast_layer = pretrained_model.get_layer('block5_pool')\nlast_output = last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(1, activation='sigmoid')(x)           \n\nmodel_vgg = Model(pretrained_model.input, x) \n\n\nmodel_vgg.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:04:48.282832Z","iopub.execute_input":"2023-01-19T14:04:48.283188Z","iopub.status.idle":"2023-01-19T14:04:51.722883Z","shell.execute_reply.started":"2023-01-19T14:04:48.283158Z","shell.execute_reply":"2023-01-19T14:04:51.721935Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2023-01-19 14:04:48.392601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-19 14:04:48.396023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-19 14:04:48.396785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-19 14:04:48.397677: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-19 14:04:48.398053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-19 14:04:48.398793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-19 14:04:48.399463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-19 14:04:50.549041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-19 14:04:50.549944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-19 14:04:50.550645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-19 14:04:50.551236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15381 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 120, 120, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 120, 120, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 120, 120, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 60, 60, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 60, 60, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 60, 60, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 30, 30, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 30, 30, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 30, 30, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 30, 30, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 15, 15, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 15, 15, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 7, 7, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 7, 7, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 7, 7, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 0\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Obtaining DF from Images**\n* ### The data being used for training is already good. Both the classes are perfectly balanced in either of the datasets.\n* ### Images have been stored into dataframes alongwith labels for further ease of access.","metadata":{}},{"cell_type":"code","source":"positive_dir = Path('../input/surface-crack-detection/Positive')\nnegative_dir = Path('../input/surface-crack-detection/Negative')\n\n\ndef generate_df(image_dir, label):\n    filepaths = pd.Series(list(image_dir.glob(r'*.jpg')), name='Filepath').astype(str)\n    labels = pd.Series(label, name='Label', index=filepaths.index)\n    df = pd.concat([filepaths, labels], axis=1)\n    return df\npositive_df = generate_df(positive_dir, label=\"POSITIVE\")\nnegative_df = generate_df(negative_dir, label=\"NEGATIVE\")\n\n\nall_df = pd.concat([positive_df, negative_df], axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\nall_df","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:06:01.233206Z","iopub.execute_input":"2023-01-19T14:06:01.233915Z","iopub.status.idle":"2023-01-19T14:06:01.598191Z","shell.execute_reply.started":"2023-01-19T14:06:01.233878Z","shell.execute_reply":"2023-01-19T14:06:01.597175Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                Filepath     Label\n0      ../input/surface-crack-detection/Positive/0574...  POSITIVE\n1      ../input/surface-crack-detection/Positive/1870...  POSITIVE\n2      ../input/surface-crack-detection/Positive/0967...  POSITIVE\n3      ../input/surface-crack-detection/Negative/0791...  NEGATIVE\n4      ../input/surface-crack-detection/Positive/1400...  POSITIVE\n...                                                  ...       ...\n39995  ../input/surface-crack-detection/Positive/0854...  POSITIVE\n39996  ../input/surface-crack-detection/Negative/1944...  NEGATIVE\n39997  ../input/surface-crack-detection/Positive/0977...  POSITIVE\n39998  ../input/surface-crack-detection/Positive/1504...  POSITIVE\n39999  ../input/surface-crack-detection/Negative/1099...  NEGATIVE\n\n[40000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filepath</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/surface-crack-detection/Positive/0574...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/surface-crack-detection/Positive/1870...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/surface-crack-detection/Positive/0967...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/surface-crack-detection/Negative/0791...</td>\n      <td>NEGATIVE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/surface-crack-detection/Positive/1400...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39995</th>\n      <td>../input/surface-crack-detection/Positive/0854...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>39996</th>\n      <td>../input/surface-crack-detection/Negative/1944...</td>\n      <td>NEGATIVE</td>\n    </tr>\n    <tr>\n      <th>39997</th>\n      <td>../input/surface-crack-detection/Positive/0977...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>39998</th>\n      <td>../input/surface-crack-detection/Positive/1504...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>39999</th>\n      <td>../input/surface-crack-detection/Negative/1099...</td>\n      <td>NEGATIVE</td>\n    </tr>\n  </tbody>\n</table>\n<p>40000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Splitting into Train and Test**","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(\n    all_df.sample(40000, random_state=1),\n    train_size=0.7,\n    shuffle=True,\n    random_state=1\n)\n\ntrain_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntest_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:06:06.052048Z","iopub.execute_input":"2023-01-19T14:06:06.052425Z","iopub.status.idle":"2023-01-19T14:06:06.069615Z","shell.execute_reply.started":"2023-01-19T14:06:06.052395Z","shell.execute_reply":"2023-01-19T14:06:06.068743Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# **Train data**","metadata":{}},{"cell_type":"code","source":"train_data = train_gen.flow_from_dataframe(\n    train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:06:10.092417Z","iopub.execute_input":"2023-01-19T14:06:10.092787Z","iopub.status.idle":"2023-01-19T14:06:23.985150Z","shell.execute_reply.started":"2023-01-19T14:06:10.092754Z","shell.execute_reply":"2023-01-19T14:06:23.984079Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Found 22400 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Validation data**","metadata":{}},{"cell_type":"code","source":"val_data = train_gen.flow_from_dataframe(\n    train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:06:23.987031Z","iopub.execute_input":"2023-01-19T14:06:23.989508Z","iopub.status.idle":"2023-01-19T14:06:37.986194Z","shell.execute_reply.started":"2023-01-19T14:06:23.989477Z","shell.execute_reply":"2023-01-19T14:06:37.985299Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Found 5600 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Test data**","metadata":{}},{"cell_type":"code","source":"test_data = train_gen.flow_from_dataframe(\n    test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=False,\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:06:37.990708Z","iopub.execute_input":"2023-01-19T14:06:37.992954Z","iopub.status.idle":"2023-01-19T14:07:05.300085Z","shell.execute_reply.started":"2023-01-19T14:06:37.992915Z","shell.execute_reply":"2023-01-19T14:07:05.298901Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Found 12000 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Model Training**\n\n### Using 10 epochs and early loss to prevent overfitting","metadata":{}},{"cell_type":"code","source":"history = model_vgg.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=10,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:07:18.407460Z","iopub.execute_input":"2023-01-19T14:07:18.407814Z","iopub.status.idle":"2023-01-19T14:17:31.096537Z","shell.execute_reply.started":"2023-01-19T14:07:18.407785Z","shell.execute_reply":"2023-01-19T14:17:31.095513Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2023-01-19 14:07:18.732004: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2023-01-19 14:07:20.688143: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"700/700 [==============================] - 165s 225ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.0147 - val_accuracy: 0.9962\nEpoch 2/10\n700/700 [==============================] - 63s 91ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0135 - val_accuracy: 0.9962\nEpoch 3/10\n700/700 [==============================] - 62s 88ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0145 - val_accuracy: 0.9962\nEpoch 4/10\n700/700 [==============================] - 62s 89ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.0134 - val_accuracy: 0.9961\nEpoch 5/10\n700/700 [==============================] - 61s 87ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0129 - val_accuracy: 0.9964\nEpoch 6/10\n700/700 [==============================] - 62s 89ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.0133 - val_accuracy: 0.9970\nEpoch 7/10\n700/700 [==============================] - 68s 97ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0143 - val_accuracy: 0.9961\nEpoch 8/10\n700/700 [==============================] - 68s 98ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0138 - val_accuracy: 0.9968\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Custom Image Input**\n### Simple way to directly give a random image as an input to the model for detection","metadata":{}},{"cell_type":"code","source":"img = cv2.imread('/kaggle/input/personal-for-crack-images/nocrack.jpg')\nimg = cv2.resize(img, (120,120))\nimg = np.array(img)\nimg = np.expand_dims(img,axis=0)\ny_pred = np.squeeze((model_vgg.predict(img) >= 0.5).astype(np.int))\nprint(y_pred) # 0 is for no crack and 1 for crack","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:50:23.473657Z","iopub.execute_input":"2023-01-19T14:50:23.474085Z","iopub.status.idle":"2023-01-19T14:50:23.557921Z","shell.execute_reply.started":"2023-01-19T14:50:23.474051Z","shell.execute_reply":"2023-01-19T14:50:23.556670Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Model Evaluation Function**","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, test_data):\n    \n    results = model.evaluate(test_data, verbose=0)\n    loss = results[0]\n    acc = results[1]\n    \n    print(\"    Test Loss: {:.5f}\".format(loss))\n    print(\"Test Accuracy: {:.2f}%\".format(acc * 100))\n    \n    y_pred = np.squeeze((model.predict(test_data) >= 0.5).astype(np.int))\n    cm = confusion_matrix(test_data.labels, y_pred)\n    clr = classification_report(test_data.labels, y_pred, target_names=[\"NEGATIVE\", \"POSITIVE\"])\n    \n    plt.figure(figsize=(6, 6))\n    sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n    plt.xticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\n    plt.yticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    \n    print(\"Classification Report:\\n----------------------\\n\", clr)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:20:52.614613Z","iopub.execute_input":"2023-01-19T14:20:52.615189Z","iopub.status.idle":"2023-01-19T14:20:52.633626Z","shell.execute_reply.started":"2023-01-19T14:20:52.615146Z","shell.execute_reply":"2023-01-19T14:20:52.632697Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# **Generate Test DF**\n## Obtaining Test dataframe from the test data of given dataset for model evaluation","metadata":{}},{"cell_type":"code","source":"#Obtain actual test DF for checking\nactual_positive_dir = Path('/kaggle/input/surface-crack/test/Positive')\nactual_negative_dir = Path('/kaggle/input/surface-crack/test/Negative')\n\nactual_positive_df = generate_df(actual_positive_dir, label=\"POSITIVE\")\nactual_negative_df = generate_df(actual_negative_dir, label=\"NEGATIVE\")\n\nactual_all_df = pd.concat([actual_positive_df, actual_negative_df], axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\nactual_all_df\n\nactual_test_data = train_gen.flow_from_dataframe(\n    actual_all_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=False,\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:22:30.083351Z","iopub.execute_input":"2023-01-19T14:22:30.083722Z","iopub.status.idle":"2023-01-19T14:22:30.194734Z","shell.execute_reply.started":"2023-01-19T14:22:30.083693Z","shell.execute_reply":"2023-01-19T14:22:30.193799Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Found 200 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Model Performance Evaluation**","metadata":{}},{"cell_type":"code","source":"evaluate_model(model_vgg, actual_test_data)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:28:16.687458Z","iopub.execute_input":"2023-01-19T14:28:16.688051Z","iopub.status.idle":"2023-01-19T14:28:17.900628Z","shell.execute_reply.started":"2023-01-19T14:28:16.688018Z","shell.execute_reply":"2023-01-19T14:28:17.899210Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"    Test Loss: 0.02050\nTest Accuracy: 99.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x432 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"Classification Report:\n----------------------\n               precision    recall  f1-score   support\n\n    NEGATIVE       0.98      1.00      0.99       100\n    POSITIVE       1.00      0.98      0.99       100\n\n    accuracy                           0.99       200\n   macro avg       0.99      0.99      0.99       200\nweighted avg       0.99      0.99      0.99       200\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Thus, the model has the following performance metrics:\n* ### Precision - 98% for NEGATIVE and 100% for POSITIVE\n* ### Recall - 100% for NEGATIVE and 98% for POSITIVE\n* ### F1 Score - 99%\n* ### Accuracy of 99%\n* ### Test Loss - 0.02050","metadata":{}},{"cell_type":"markdown","source":"# **Saving and Loading Model**\n### The model can easily be exported for direct use elsewhere without having the need to retrain the model.","metadata":{"execution":{"iopub.status.busy":"2023-01-19T14:23:09.438903Z","iopub.execute_input":"2023-01-19T14:23:09.439255Z","iopub.status.idle":"2023-01-19T14:23:09.612100Z","shell.execute_reply.started":"2023-01-19T14:23:09.439224Z","shell.execute_reply":"2023-01-19T14:23:09.611155Z"}}},{"cell_type":"code","source":"!ls /kaggle/working\nmodel_vgg.save('/kaggle/working/Crack_Detection_VGG16_model_final.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-19T15:05:55.445604Z","iopub.execute_input":"2023-01-19T15:05:55.445978Z","iopub.status.idle":"2023-01-19T15:05:56.653730Z","shell.execute_reply.started":"2023-01-19T15:05:55.445947Z","shell.execute_reply":"2023-01-19T15:05:56.652493Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Crack_Detection_VGG16_model_1630PM.h5  model_pickle\n__notebook_source__.ipynb\t       model_pickle_1\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import load_model\nmp = load_model('/kaggle/working/Crack_Detection_VGG16_model_final.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-19T15:02:34.778043Z","iopub.execute_input":"2023-01-19T15:02:34.778425Z","iopub.status.idle":"2023-01-19T15:02:35.180651Z","shell.execute_reply.started":"2023-01-19T15:02:34.778394Z","shell.execute_reply":"2023-01-19T15:02:35.178808Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}]}]}